{"cells":[{"cell_type":"code","source":["!pip install gdown==4.4.0"],"metadata":{"id":"yY51d2f7nEgZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":1,"metadata":{"id":"i6fGSKomlrjz","executionInfo":{"status":"ok","timestamp":1647599937695,"user_tz":-180,"elapsed":1067,"user":{"displayName":"TheYellowBlueWhite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAfvaa-WCLwvejzOyZX8Vo-5gMIz38Tc5WT5vU=s64","userId":"06339693875169464138"}}},"outputs":[],"source":["import numpy as np\n","import os\n","import torch\n","import torch.nn as nn"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"ljFEQOhFlrj9","executionInfo":{"status":"ok","timestamp":1647600626016,"user_tz":-180,"elapsed":516,"user":{"displayName":"TheYellowBlueWhite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAfvaa-WCLwvejzOyZX8Vo-5gMIz38Tc5WT5vU=s64","userId":"06339693875169464138"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import models \n","\n","def weights_init(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        nn.init.normal_(m.weight.data, 0.0, 0.02)\n","    elif classname.find('BatchNorm') != -1:\n","        nn.init.normal_(m.weight.data, 1.0, 0.02)\n","        nn.init.constant_(m.bias.data, 0)\n","\n","class CelebaEncoder(nn.Module):\n","    \"\"\" Celeba Encoder\n","        Args:\n","            init_num_filters (int): initial number of filters from encoder image channels\n","            lrelu_slope (float): positive number indicating LeakyReLU negative slope\n","            inter_fc_dim (int): intermediate fully connected dimensionality prior to embedding layer\n","            embedding_dim (int): embedding dimensionality\n","    \"\"\"\n","    def __init__(self, init_num_filters=16, lrelu_slope=0.2, embedding_dim=128, nc=3, dropout=0.05):\n","        super(CelebaEncoder, self).__init__()\n","\n","        self.init_num_filters_ = init_num_filters\n","        self.lrelu_slope_ = lrelu_slope\n","        self.embedding_dim_ = embedding_dim\n","\n","        self.features = nn.Sequential(\n","            nn.Conv2d(nc,  self.init_num_filters_ * 1, 4, 2, 1, bias=False),\n","            nn.LeakyReLU(self.lrelu_slope_, inplace=True),\n","            nn.Dropout(dropout),\n","            \n","            # state size. (ndf) x 32 x 32\n","            nn.Conv2d(self.init_num_filters_, self.init_num_filters_ * 2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(self.init_num_filters_ * 2),\n","            nn.LeakyReLU(self.lrelu_slope_, inplace=True),\n","            nn.Dropout(dropout),\n","            \n","            # state size. (ndf*2) x 16 x 16\n","            nn.Conv2d(self.init_num_filters_  * 2, self.init_num_filters_ * 4, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(self.init_num_filters_  * 4),\n","            nn.LeakyReLU(self.lrelu_slope_, inplace=True),\n","            nn.Dropout(dropout),\n","            \n","            # state size. (ndf*4) x 8 x 8\n","            nn.Conv2d(self.init_num_filters_  * 4, self.init_num_filters_ * 8, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(self.init_num_filters_  * 8),\n","            nn.LeakyReLU(self.lrelu_slope_, inplace=True),\n","            nn.Dropout(dropout),\n","            \n","            # state size. (ndf*8) x 4 x 4\n","            nn.Conv2d(self.init_num_filters_ * 8, self.init_num_filters_ * 8, 4, 2, 0, bias=False),\n","        )\n","        \n","        self.fc_out = nn.Sequential(\n","            nn.Linear(self.init_num_filters_ * 8, self.embedding_dim_),\n","            nn.Tanh()\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = x.flatten(start_dim=1)\n","        x = self.fc_out(x)\n","        return x\n","\n","class CelebaDecoder(nn.Module):\n","    \"\"\" Celeba Decoder\n","        Args:\n","            init_num_filters (int): initial number of filters from encoder image channels\n","            lrelu_slope (float): positive number indicating LeakyReLU negative slope\n","            inter_fc_dim (int): intermediate fully connected dimensionality prior to embedding layer\n","            embedding_dim (int): embedding dimensionality\n","    \"\"\"\n","    def __init__(self, init_num_filters=16, lrelu_slope=0.2, embedding_dim=128, nc=3, dropout=0.05):\n","        super(CelebaDecoder, self).__init__()\n","\n","        self.init_num_filters_ = init_num_filters\n","        self.lrelu_slope_ = lrelu_slope\n","        self.embedding_dim_ = embedding_dim\n","\n","        self.features = nn.Sequential(\n","            nn.Upsample(scale_factor=2, mode='nearest'),\n","            nn.Conv2d(self.init_num_filters_ * 8, self.init_num_filters_ * 8, 3, 1, 1, bias=False),\n","            nn.BatchNorm2d(self.init_num_filters_ * 8),\n","            nn.LeakyReLU(lrelu_slope, inplace=True),\n","            nn.Dropout(dropout),\n","            \n","            nn.Upsample(scale_factor=2, mode='nearest'),\n","            nn.Conv2d(self.init_num_filters_ * 8, self.init_num_filters_ * 4, 3, 1, 1, bias=False),\n","            nn.BatchNorm2d(self.init_num_filters_ * 4),\n","            nn.LeakyReLU(lrelu_slope, inplace=True),\n","            nn.Dropout(dropout),\n","\n","            nn.Upsample(scale_factor=2, mode='nearest'),\n","            nn.Conv2d(self.init_num_filters_ * 4, self.init_num_filters_ * 2, 3, 1, 1, bias=False),\n","            nn.BatchNorm2d(self.init_num_filters_ * 2),\n","            nn.LeakyReLU(lrelu_slope, inplace=True),\n","            nn.Dropout(dropout),\n","            \n","            nn.Upsample(scale_factor=2, mode='nearest'),\n","            nn.Conv2d(self.init_num_filters_ * 2, self.init_num_filters_ * 1, 3, 1, 1, bias=False),\n","            nn.BatchNorm2d(self.init_num_filters_ * 1),\n","            nn.LeakyReLU(lrelu_slope, inplace=True),\n","            nn.Dropout(dropout),\n","            \n","            nn.Upsample(scale_factor=2, mode='nearest'),\n","            nn.Conv2d(self.init_num_filters_ * 1, nc, 3, 1, 1, bias=False),\n","            nn.Tanh()\n","        )\n","        \n","        self.fc_in = nn.Sequential(\n","            nn.Linear(self.embedding_dim_, self.init_num_filters_ * 8 * 4),\n","            nn.LeakyReLU(self.lrelu_slope_, inplace=True),\n","        )\n","\n","    def forward(self, z):\n","        z = self.fc_in(z)\n","        z = z.view(-1, self.init_num_filters_ * 8, 2, 2)\n","        z = self.features(z)\n","        return z\n","    \n","class CelebaAutoencoder(nn.Module):\n","    \"\"\" Celeba Autoencoder\n","        Args:\n","            init_num_filters (int): initial number of filters from encoder image channels\n","            lrelu_slope (float): positive number indicating LeakyReLU negative slope\n","            inter_fc_dim (int): intermediate fully connected dimensionality prior to embedding layer\n","            embedding_dim (int): embedding dimensionality\n","    \"\"\"\n","    def __init__(self, init_num_filters=16, lrelu_slope=0.2, inter_fc_dim=128, embedding_dim=2, conv_init='normal'):\n","        super(CelebaAutoencoder, self).__init__()\n","\n","        self.init_num_filters_ = init_num_filters\n","        self.lrelu_slope_ = lrelu_slope\n","        self.inter_fc_dim_ = inter_fc_dim\n","        self.embedding_dim_ = embedding_dim\n","\n","        self.encoder = CelebaEncoder(init_num_filters, lrelu_slope, embedding_dim)\n","        self.decoder = CelebaDecoder(init_num_filters, lrelu_slope, embedding_dim)\n","\n","        if conv_init == 'normal':\n","            for m in self.modules():\n","                m.apply(weights_init)\n","        else:\n","            raise NotImplementedError()\n","\n","    def forward(self, x):\n","        z = self.encoder(x)\n","        return self.decoder(z)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0m0FsBDGlrkD","executionInfo":{"status":"ok","timestamp":1647600627249,"user_tz":-180,"elapsed":6,"user":{"displayName":"TheYellowBlueWhite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAfvaa-WCLwvejzOyZX8Vo-5gMIz38Tc5WT5vU=s64","userId":"06339693875169464138"}},"outputId":"5967d48f-a721-449d-c9b9-89bf55d31d07"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 128])\n","torch.Size([1, 3, 64, 64])\n"]}],"source":["dummy = torch.randn((1, 3, 64, 64))\n","\n","enc = CelebaEncoder()\n","dec = CelebaDecoder()\n","\n","emb = enc(dummy)\n","print(emb.size())\n","rec = dec(emb)\n","print(rec.size())"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"RgTXxpVklrkJ","executionInfo":{"status":"ok","timestamp":1647600628371,"user_tz":-180,"elapsed":3,"user":{"displayName":"TheYellowBlueWhite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAfvaa-WCLwvejzOyZX8Vo-5gMIz38Tc5WT5vU=s64","userId":"06339693875169464138"}}},"outputs":[],"source":["from torchvision.utils import make_grid, save_image\n","import matplotlib.pyplot as plt\n","\n","\n","def plot_img(img, name):\n","    img = img.detach().cpu().numpy()\n","    plt.imshow(np.transpose(img, (1, 2, 0)))\n","    plt.savefig(name)\n","\n","\n","def train(train_loader, model, optimizer, criterion,\n","          device, lr_schedule=None):\n","    loss_sum = 0.0\n","    num_iters = len(train_loader)\n","    model.train()\n","    rand_batch = np.random.randint(0, num_iters)\n","    for idx, inp in enumerate(train_loader):\n","        if lr_schedule is not None:\n","            lr = lr_schedule(idx / num_iters)\n","            adjust_learning_rate(optimizer, lr)\n","\n","        inp = inp.to(device)\n","        optimizer.zero_grad()\n","        \n","        output = model(inp)\n","        loss = criterion(inp, output)\n","        \n","        loss.backward()\n","        optimizer.step()\n","\n","        with torch.no_grad():\n","            if idx == rand_batch:\n","                print_images = torch.cat([inp, output], dim=3)\n","                grid = make_grid(print_images, nrow=8, normalize=False)\n","                plot_img(grid.detach().cpu(), 'train_{}.jpg'.format(idx))\n","                \n","        loss_sum += loss.item()\n","\n","    return {\n","        'loss': loss_sum / num_iters\n","    }\n","\n","\n","def test(test_loader, model, criterion,\n","         device):\n","    loss_sum = 0.0\n","    model.eval()\n","    num_iters = len(test_loader)\n","    rand_batch = np.random.randint(0, num_iters)\n","    for idx, inp in enumerate(test_loader):\n","        inp = inp.to(device)\n","\n","        with torch.no_grad():\n","            output = model(inp)\n","            loss = criterion(inp, output)\n","\n","        with torch.no_grad():\n","            if idx == rand_batch:\n","                print_images = torch.cat([inp, output], dim=3)\n","                grid = make_grid(print_images, nrow=8, normalize=False)\n","                save_image(grid.detach().cpu(), fp='imgs/test_{}.jpg'.format(idx))\n","\n","        loss_sum += loss.item()\n","\n","    return {\n","        'loss': loss_sum / num_iters\n","    }"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"rDgRw41ElrkK","executionInfo":{"status":"ok","timestamp":1647602112936,"user_tz":-180,"elapsed":4652,"user":{"displayName":"TheYellowBlueWhite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAfvaa-WCLwvejzOyZX8Vo-5gMIz38Tc5WT5vU=s64","userId":"06339693875169464138"}}},"outputs":[],"source":["import torch.optim as optim\n","import dataset\n","\n","b_size = 128\n","device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n","base_lr = 1e-4\n","\n","loaders = dataset.build_loader(\n","    dataset.CelebADataset,\n","    'data',\n","    b_size,\n","    2\n",")"]},{"cell_type":"code","source":["model = CelebaAutoencoder(init_num_filters=32)\n","model = model.to(device)\n","\n","opt = optim.Adam(model.parameters(), lr=base_lr, weight_decay=1e-8)"],"metadata":{"id":"5sKd84CappXK","executionInfo":{"status":"ok","timestamp":1647602112938,"user_tz":-180,"elapsed":14,"user":{"displayName":"TheYellowBlueWhite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAfvaa-WCLwvejzOyZX8Vo-5gMIz38Tc5WT5vU=s64","userId":"06339693875169464138"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["print(np.sum([np.prod(list(p.shape)) for p in model.parameters()]), 'params in AutoEncoder')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5UdJ2tRur9ed","executionInfo":{"status":"ok","timestamp":1647601282880,"user_tz":-180,"elapsed":13,"user":{"displayName":"TheYellowBlueWhite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAfvaa-WCLwvejzOyZX8Vo-5gMIz38Tc5WT5vU=s64","userId":"06339693875169464138"}},"outputId":"46d5fff3-678a-4786-b6b3-5b7e954c16de"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["2721442 params in AutoEncoder\n"]}]},{"cell_type":"code","execution_count":26,"metadata":{"id":"snNxKHRXlrkM","executionInfo":{"status":"ok","timestamp":1647601284331,"user_tz":-180,"elapsed":6,"user":{"displayName":"TheYellowBlueWhite","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAfvaa-WCLwvejzOyZX8Vo-5gMIz38Tc5WT5vU=s64","userId":"06339693875169464138"}}},"outputs":[],"source":["def learning_rate_schedule(base_lr, epoch, total_epochs):\n","    alpha = epoch / total_epochs\n","    if alpha <= 0.5:\n","        factor = 1.0\n","    elif alpha <= 0.9:\n","        factor = 1.0 - (alpha - 0.5) / 0.4 * 0.99\n","    else:\n","        factor = 0.01\n","    return factor * base_lr\n","\n","def adjust_learning_rate(optimizer, lr):\n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] = lr\n","    return lr"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uXU7dlELlrkO","outputId":"b3a644c3-4e41-4bcc-f78f-151d8ebd6a27"},"outputs":[{"output_type":"stream","name":"stderr","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"]},{"output_type":"stream","name":"stdout","text":["[Epoch]: 0, Train loss: 0.16963877804853297, Test loss: None, time elaplsed: 3.069\n"]},{"output_type":"stream","name":"stderr","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"]},{"output_type":"stream","name":"stdout","text":["[Epoch]: 1, Train loss: 0.1558675419300895, Test loss: None, time elaplsed: 3.034\n"]},{"output_type":"stream","name":"stderr","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"]},{"output_type":"stream","name":"stdout","text":["[Epoch]: 2, Train loss: 0.15382722840465682, Test loss: None, time elaplsed: 3.023\n"]},{"output_type":"stream","name":"stderr","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"]},{"output_type":"stream","name":"stdout","text":["[Epoch]: 3, Train loss: 0.15249412753917152, Test loss: None, time elaplsed: 3.001\n"]},{"output_type":"stream","name":"stderr","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"]},{"output_type":"stream","name":"stdout","text":["[Epoch]: 4, Train loss: 0.15166372418253107, Test loss: None, time elaplsed: 2.980\n"]},{"output_type":"stream","name":"stderr","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"]},{"output_type":"stream","name":"stdout","text":["[Epoch]: 5, Train loss: 0.15102593057635255, Test loss: None, time elaplsed: 2.984\n"]},{"output_type":"stream","name":"stderr","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"]},{"output_type":"stream","name":"stdout","text":["[Epoch]: 6, Train loss: 0.15070591927176774, Test loss: None, time elaplsed: 2.974\n"]},{"output_type":"stream","name":"stderr","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"]},{"output_type":"stream","name":"stdout","text":["[Epoch]: 7, Train loss: 0.15022706827431015, Test loss: None, time elaplsed: 2.964\n"]},{"output_type":"stream","name":"stderr","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"]},{"output_type":"stream","name":"stdout","text":["[Epoch]: 8, Train loss: 0.14988604559240115, Test loss: None, time elaplsed: 2.970\n"]},{"output_type":"stream","name":"stderr","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"]},{"output_type":"stream","name":"stdout","text":["[Epoch]: 9, Train loss: 0.14968018036849973, Test loss: None, time elaplsed: 2.976\n"]},{"output_type":"stream","name":"stderr","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"]},{"output_type":"stream","name":"stdout","text":["[Epoch]: 10, Train loss: 0.14937034886493425, Test loss: None, time elaplsed: 3.020\n"]},{"output_type":"stream","name":"stderr","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"]},{"output_type":"stream","name":"stdout","text":["[Epoch]: 11, Train loss: 0.14919319732572495, Test loss: None, time elaplsed: 2.963\n"]},{"output_type":"stream","name":"stderr","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"]},{"output_type":"stream","name":"stdout","text":["[Epoch]: 12, Train loss: 0.1489880167399392, Test loss: None, time elaplsed: 2.981\n"]},{"output_type":"stream","name":"stderr","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"]},{"output_type":"stream","name":"stdout","text":["[Epoch]: 13, Train loss: 0.14882057767223428, Test loss: None, time elaplsed: 2.978\n"]},{"output_type":"stream","name":"stderr","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"]},{"output_type":"stream","name":"stdout","text":["[Epoch]: 14, Train loss: 0.14877844024888595, Test loss: None, time elaplsed: 3.012\n"]},{"output_type":"stream","name":"stderr","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"]},{"output_type":"stream","name":"stdout","text":["[Epoch]: 15, Train loss: 0.1485369990670721, Test loss: None, time elaplsed: 2.985\n"]},{"output_type":"stream","name":"stderr","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"]}],"source":["import time\n","import tqdm.auto as tqdm\n","start_epoch = 0\n","max_epochs = 40\n","\n","criterion = nn.L1Loss()\n","\n","test_res = {'loss': None}\n","for epoch in range(start_epoch, max_epochs+1):\n","    time_ep = time.perf_counter()\n","\n","    lr = learning_rate_schedule(base_lr, epoch, max_epochs)\n","    adjust_learning_rate(opt, lr)\n","\n","    train_res = train(loaders['train'], model, opt, criterion, device)\n","    #test_res = test(loaders['test'], model, criterion, device)\n","    time_ep = time.perf_counter() - time_ep\n","    print(f\"[Epoch]: {epoch}, Train loss: {train_res['loss']}, Test loss: {test_res['loss']}, time elaplsed: {(time_ep / 60):.3f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0FWbaYkdlrkQ"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"Untitled.ipynb","provenance":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}